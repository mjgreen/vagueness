## Model criticism for logRT model

The residuals are bad for this model.
Baayen says to drop data points for which the absolute standardized residuals of the model exceed 2.5 standard deviations, using code like below

```{r}
# example code from Baayen and Milin, 2010 "Analyzing Reaction Times"
# Baayen, R. Harald, and Petar Milin. "Analyzing reaction times." International Journal of Psychological Research 3.2 (2015): 12-28.
library(languageR) # pulls up lexdec
qqmath(~1/exp(RT) | Subject, data = lexdec, aspect=1, pch='.')

lexdec2A = lexdec2[abs(scale(resid(lexdec2.lmer))) < 2.5, ]
lexdec2A.lmer = lmer(-1000 * RTinv ~ NativeLanguage + Class +
                       + Frequency + Length + (1 | Subject) + (1 | Word), data = lexdec2A)
cor(fitted(lexdec2A.lmer), -1000 * lexdec2A$RTinv)^2
```

```{r, fig.width=4, fig.height=4}
dat2 = dat[abs(scale(resid(lmer.logRT.mm0))) < 2.5, ]
lmer.logRT.mm3 <- lmer(data=dat2,
                       logRT~
                         c_Num * c_Vag * c_Itm + log(Trial.s) +
                         (c_Num * c_Vag + c_Itm | Subject) )
lmer.logRT.mm3.summary <- summary(lmer.logRT.mm3)
cor(fitted(lmer.logRT.mm3), -1000 * dat2$logRT)^2
qqPlot(residuals(lmer.logRT.mm3))
```
