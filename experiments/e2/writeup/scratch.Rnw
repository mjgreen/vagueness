<!--html_document:-->
  <!--toc: true-->
  <!--toc_float: true-->
  <!--mathjax: default-->
  <!--template: default-->
  <!--code_folding: hide-->
  <!--theme: default-->
  
  ```{r print_info_on_design}
cat(paste('number of subjects = ',30,'\n',
          '---','\n',
          'number of trials per subject = ',256,'\n', 
          '---','\n',          
          'number of unique cells in the design = Item(4) * Number(2) * Vagueness(2) * Order(2) * Quantity(2) = ',4*2*2*2*2,'\n',
          'number of times a subject saw a unique cell in the design = 256 / 64 = ', 256/64,'\n',
          '---','\n',
          'number of higher-level cells in the design (abstracting over Order and Quantity) = Item(4) * Number(2) * Vagueness(2) = ',4*2*2,'\n',
          'number of times a subject saw a higher level cell in the design =  = 256 / 16 = ', 4*2*2, '\n',
          sep=''))
```


# Distributional stuff, including transformations.

```{r transformations_table, results='asis'}
x=445
lambda = c(-2,-1,-0.5, 0,0.5,1,2)

xd=data.frame(
  lambda = c(
    lambda[1],
    lambda[2],
    lambda[3],
    lambda[4],
    lambda[5],
    lambda[6],
    lambda[7]
  ),
  x=c(    
    paste("x = ", sep="", x),
    paste("x = ", sep="", x),
    paste("x = ", sep="", x),
    paste("x = ", sep="", x),
    paste("x = ", sep="", x),
    paste("x = ", sep="", x),
    paste("x = ", sep="", x)
  ),
  conventional=c(
    '$$y=\\frac{1}{x^2}$$', 
    '$$y=\\frac{1}{x}$$', 
    '$$y=\\frac{1}{\\sqrt{x}}$$', 
    '$$y=log_e(x)$$', 
    '$$y=\\sqrt{x}$$', 
    '$$y=x$$', 
    '$$y=x^2$$'
  ),
  power=c(
    '$$y=x^{-2}$$', 
    '$$y=x^{-1}$$', 
    '$$y=x^{-0.5}$$', 
    '$$y=log_e(x)$$', 
    '$$y=x^{0.5}$$', 
    '$$y=x^{1}$$', 
    '$$y=x^{2}$$'
  ),
  y=c(     
    paste("y = ", sep="", format(round(x^lambda[1],6), sc=F) ),
    paste("y = ", sep="", round(x^lambda[2],3) ),
    paste("y = ", sep="", round(x^lambda[3],3) ),
    paste("y = ", sep="", round(log(x),3) ),
    paste("y = ", sep="", round(x^lambda[5],2) ),
    paste("y = ", sep="", round(x^lambda[6],6) ),
    paste("y = ", sep="", round(x^lambda[7],6) )
  ),
  back = c(
    '$$x=y^{\\frac{1}{-2}}$$',
    '$$x=y^{\\frac{1}{-1}}$$', 
    '$$x=y^{\\frac{1}{-0.5}}$$', 
    '$$x=exp(y)$$',  
    '$$x=y^{\\frac{1}{0.5}}$$', 
    '$$x=y^{\\frac{1}{1}}$$',  
    '$$x=y^{\\frac{1}{2}}$$'
  ),
  back_lambda=c(
    '$$x=y^{1/\\lambda}$$',
    '$$x=y^{1/\\lambda}$$',
    '$$x=y^{1/\\lambda}$$',
    '$$x=exp(y)$$',  
    '$$x=y^{1/\\lambda}$$',
    '$$x=y^{1/\\lambda}$$',
    '$$x=y^{1/\\lambda}$$'
  ),
  y_back=c(  
    paste( 'x = ', (x^lambda[1]) ^ {1/lambda[1]} ,sep=""),
    paste( 'x = ', (x^lambda[2]) ^ {1/lambda[2]} ,sep=""),
    paste( 'x = ', (x^lambda[3]) ^ {1/lambda[3]} ,sep=""),
    paste( 'x = ', exp(log(x)), sep=""),
    paste( 'x = ', (x^lambda[5]) ^ {1/lambda[5]} ,sep=""),
    paste( 'x = ', (x^lambda[6]) ^ {1/lambda[6]} ,sep=""),
    paste( 'x = ', (x^lambda[7]) ^ {1/lambda[7]} ,sep="")
  )
) 

print(xtable(xd, digits=1, align=c(rep('l', times=ncol(xd)+1))), type='html', include.rownames=F, digits=1)
```


Show practice and fatigue effects vary over items.

```{r pracFatigueItms, eval=TRUE, fig.width=7, fig.height=3.5, echo=FALSE}
# Show how practice/fatigue effects vary over items
ggplot(dd, aes(y=RT_RecSqt, x=Trial)) + 
  facet_grid(~Item) + 
  theme(panel.grid=element_blank(), panel.margin = unit(0, "lines"), 
        panel.background = element_rect(fill = 'white', colour='black' ), 
        legend.position="top") + 
  scale_x_continuous("Trial") + 
  geom_point(pch=19, cex=.25, alpha=.5) + 
  stat_smooth(fill='lightblue',col="red",lwd=.5, show.legend=TRUE) + 
  theme(aspect.ratio = 1) 
```

## ols model v4, RecSqt, in progress

Pairs plot

```{r pairs, fig.width=7, fig.height=7}
pairs(dd[,c("RT_RecSqt", "Number", "Vagueness", "RTprev_RecSqt")], pch = 19, cex=.075)
```

Build the model

```{r doModelols}
## do ols model
# define datadist
dd.dd = datadist(dd)
options(datadist = "dd.dd")
# build model
v4 <- ols(data=dd, 
          RT_RecSqt ~ 
            c_Vag + c_Num + c_Qty + c_Ord + 
            c_Num:c_Vag:c_Qty+
            item_mean_ratio + 
            #c_Vag:c_Num + 
            #c_Vag:c_Num:item_mean_ratio + 
            # pol(s_Trl, 3) +
            s_Trl+
            # pol(RTprev_RecSqt,3) +
            RTprev_RecSqt +
            nchar_instr
          # cell+
          # measurement,
          ,
          x=T, y=T )
```

```{r likRat}
# print out p value for likelihood ratio with df
cat("lik.ratio p value, whether the model as a whole is explanatory: p =", 1-pchisq(v4$stats[2],v4$stats[3]))
# print out R2 for the model
cat("R^2 = ", v4$stats[4])
```

Show the model tables

```{r modTabs}
# show model
v4
# show model summary
summary(v4)
# do anova 
an1 = anova(v4)
# show anova
an1
```

plot 'partial effects'

```{r partial, fig.width=12, fig.height=5}
## plot partial effects
# Compute Predicted Values and Confidence Limits
p1=Predict(v4)
# plot 'partial effects'
plot(p1, anova=an1, pval=T, aspect=1, main="ols model v4")
```

```{r daz99}
# add predicted RT_RecSqt to dd
dd$RT_Predicted <- predict (v4)
```

Plot model coefficients and ci's

```{r coefsAndCiS}
par(las=2, mar=c(14,6,1,1))
y=coef(v4) # with intercept
n=length(y)
y0=confint(v4)[,1]
y1=confint(v4)[,2]
y=coef(v4)[-1] # omit intercept
n=length(y)
y0=confint(v4)[-1,1]
y1=confint(v4)[-1,2]
plot(y, xaxt="n", xlab="", ylab="RT_RecSqt\n", pch=19, ylim=extendrange(y, f=.10), main="Speed")
abline(h=0)
axis(1, labels=names(y) , at=1:n)
grid()
segments(x0=1:n, x1=1:n, y0, y1, lwd=2)
```

Collinearity is assessed by the condition number $k$.\
The greater the collinearity, the closer the matrix of predictors is is to becoming _singular_.\
$k$ estimates the extent to which a matrix is $\text{singular}$\
$0\ldots6$ no collinearity\
$\text{around} 15$ medium collinearity\
$>30$ indicates potentially harmful collinearity\

```{r kis}
cat("k is:",
collin.fnc(dd[,	c("s_Trl", "c_Num", "c_Vag", "c_Qty", "c_Ord", "item_mean_ratio", 
"RTprev_RecSqt", "nchar_instr", "measurement")
])$cnumber
)
```

```{r plotg, fig.width=6, fig.height=5}
par(mar=c(1.1,3.1,1.1,1.1), pty='s')
plot(varclus(
as.matrix(dd[,c("s_Trl", "c_Num", "c_Vag", "c_Qty", "c_Ord",
"item_mean_ratio", "RTprev_RecSqt", "nchar_instr", "measurement")])))
```

Model criticism baayen plots

```{r baayenMplots, fig.width=9, fig.height=3}
# Baayen 4-plot model criticism
par(mfrow=c(1,4), pty='s')
# create scaled residuals
v4$rstand = as.vector(scale(resid(v4)))
# plot scaled residuals density
plot(density(v4$rstand), main='density of\nscaled residuals')
# plot sample quantiles versus theoretical quantiles
qqnorm(v4$rstand, cex=.5)
qqline(v4$rstand)
# plot standardised residuals versus fitted values
plot(v4$rstand ~ fitted(v4), pch='.', main='std resid\nv fitted')
# absolute standardised residuals greater than 2.5 are candidates 
# for being outliers, the abline identifies them on the plot
abline(h=c(-2.5,2.5))
# create dffits
dffits=abs(resid(v4, "dffits"))
# plot dffits
plot(dffits, type='h', main='dffits')
# here no overly influential
w = which.influence(fit = v4, cutoff = 0.4)
if (length(w)==0) {
print('There are no overly influential data points')
} else {
print('There are some overly influential variables:');
print(w)
}
```

Model validation

Validation tests overfitting using bootstrap.

Bootstrapping draws as a bootstrap sample the same number of samples as the original data, at random with replacement, from the original data.

Then fit the model to the data in the bootstrap sample, and use this model to predict the reaction times for the original full data (which contains many samples that are new to the bootstrap model).

Then compare the goodness of fit of the bootstrap model with the goodness of fit of the original model.

Averaged over a large number of bootstrap models these comparisons of goodness of fit  reveal to what extent the original model overfits the data.

Function validate() in rms does this _re-sampling validation_.


```{r val_1, echo=TRUE}
# argument B is the number of bootstrap runs
# argument pr is whether to print the results of each run
v_1 <- validate(v4, bw = T, B = 200, pr=FALSE, estimates=TRUE)
```

```{r prval}
# in print.validate, B is the number of re-samples to show outocmes for each resample
print(v_1, B=0)
```

```{r kept}
# show how often each number of variables kept was observed across the 200 runs
xtabs(~rowSums(attr(v_1,"kept")))
```



  
<<exampleOfFonts, fig.width=3, fig.height=3, fig.cap='font example', echo=FALSE, eval=FALSE>>=
p <- ggplot(mtcars, aes(x=wt, y=mpg)) + geom_point() +
ggtitle("Fuel Efficiency of 32 Cars") +
xlab("Weight (x1000 lb)") + ylab("Miles per Gallon") +
theme_bw() +
theme(text=element_text(family="CMU Serif", size=14, face='plain'))
p
ggsave("ggplot_CMU_Serif.pdf", p, width=3.5, height=3.5)
@


<<defineFonts>>=
# .define.fonts <- function () {
#     quartzFonts(avenir =    c('Avenir Book', 'Avenir Black', 'Avenir Book Oblique', 'Avenir Black Oblique'),
#                 helvetica = c('Helvetica New Light', 'Helvetica New Bold', 'Helvetica New Light Italic', 'Helvetica New Bold Italic'),
#                 cmodern = c('CMU Serif', 'CMU Serif Extra','CMU Classical Serif','CMU Serif Extra'))
# }
# .define.fonts()
@

<<fig.cap='base graphic special font'>>=
#base graphic special font
pdf("plot_cm.pdf", family="CM Roman", width=5.5, height=5)

curve(dnorm, from=-3, to=3, main="Normal Distribution")
text(x=0, y=0.1, cex=1.5, expression(italic(y == frac(1, sqrt(2 * pi)) *
e ^ {-frac(x^2, 2)} )))

dev.off()
embed_fonts("plot_cm.pdf", outfile="plot_cm_embed.pdf")
@

