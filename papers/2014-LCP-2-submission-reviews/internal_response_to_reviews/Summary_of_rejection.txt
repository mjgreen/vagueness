I suspect that the main empirical contribution of these data is related to verification procedures (rather than to game theoretic notions)


Verification procedures -- selection algorithms
a) “comparison algorithm” (which square has more dots?) 
c) “matching algorithm”  (which square has n dots)

Main effects in e1 and e2 are due to a difference in selection algorithm. Ok, but if it's the vague language that effects the transition between algorithms, then it is vagueness that underlies the effects. Not if “comparison” is required for more/many and “matching” is required for “10” even in the absence of a vagueness difference.

E3 verbal conditions require comparison algorithm
E3 numerical conditions require a matching algorithm

It is my recommendation that this potential confound be addressed before this work is published.


Research question: Within the comparison algorithm, is vagueness better than crispness?

Null hypothesis: Within the comparison algorithm, there is no difference between vagueness and crispness

 1) to eliminate the confound due to type of selection algorithm, one might compare ‘find the/a square with many dots’ to ‘find the/a square with more than 10 dots’, as both of these would be solvable with a comparison algorithm. My own intuition is that the ‘many’ condition would be easier (though admittedly this doesn’t separate vagueness from verbal format).
 
 I can’t at the moment see how one would tease apart vagueness vs. numerical/verbal format without introducing other confounds, but I wonder if this would require a different sort of task than a forced choice. 
 
Research question: Within verbal format, does the comparison algorithm result in better performance than the matching algorithm?

Null hypothesis: there is no difference due to the algorithm used.
 
 2) To test comparison vs. matching directly, one might eliminate the linguistic/numerical version of the specification as follows: first show one array of dots, then 2/3 arrays with the instruction ‘find the square with the same number of dots’ or ‘find the square with more dots’ (or even “=” vs “>”). Similar results to those found in Exp. 3 would tend to support that the difference is due to the type of algorithm employed, and not to character (vague/precise; numerical/verbal) of the referring expression.
 
 
 Cite Dehaene 1997, Feigenson et al. 2004, Izard & Dehaene 2008 
 
 Start with a section showing that vagueness is confounded with numerical/verbal format. Therefore we produce an acknowledgedly-confounded effect, and then separately attack a series of explanations based on “oh, it’s not vagueness (v), it’s the thing (x,y,z) that is confounded with vagueness (v) that (x,y,z) produces the effect. You’d get the effect of (x,y,x) wihout (v)”. The way you respond to that is by producing null effects of {x} {y} {z}. While these nulls do not even nearly provide support on their own as nulls, they take the wind out of the sails of the “oh, it’s the confounded-with variable that produces the effect” argument. To be convincing nulls, you have to try hard to reject them each. The power of the experments that produce nulls should be greater than the power of the experiment that detected the confounded effect.
 
 
 Measure reading RT as well as response RT
 Don’t use gap size use ratio
 Define the exact range of subitizable
 
 
 